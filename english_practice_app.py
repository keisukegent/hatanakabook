import streamlit as st
import json
import os
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import pandas as pd
import base64
import io
import tempfile
import speech_recognition as sr
from gtts import gTTS
import time
import random
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
import av
from pydub import AudioSegment
import numpy as np
from difflib import SequenceMatcher

# ã‚¢ãƒ—ãƒªã®è¨­å®š
st.set_page_config(
    page_title="ğŸ—£ï¸ English Practice App",
    page_icon="ğŸ—£ï¸",
    layout="wide"
)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
DATA_FILE = "english_practice_data.json"

# ãƒ•ãƒ¬ãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
PHRASE_DATABASE = {
    "Shopping": [
        {"english": "How much does this cost?", "japanese": "ã“ã‚Œã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "Can I get a discount?", "japanese": "å‰²å¼•ã¯ã§ãã¾ã™ã‹ï¼Ÿ", "difficulty": 2},
        {"english": "Do you have this in a different size?", "japanese": "ã“ã‚Œã®é•ã†ã‚µã‚¤ã‚ºã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ", "difficulty": 2},
        {"english": "Where is the fitting room?", "japanese": "è©¦ç€å®¤ã¯ã©ã“ã§ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "I'll take this one, please.", "japanese": "ã“ã‚Œã‚’ãã ã•ã„ã€‚", "difficulty": 1},
        {"english": "Could you wrap this as a gift?", "japanese": "ã“ã‚Œã‚’ã‚®ãƒ•ãƒˆåŒ…è£…ã—ã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ", "difficulty": 3},
    ],
    "Restaurant": [
        {"english": "Could I see the menu, please?", "japanese": "ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¦‹ã›ã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "I'd like to make a reservation.", "japanese": "äºˆç´„ã‚’ã—ãŸã„ã®ã§ã™ãŒã€‚", "difficulty": 2},
        {"english": "What do you recommend?", "japanese": "ãŠã™ã™ã‚ã¯ä½•ã§ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "I'm allergic to nuts.", "japanese": "ãƒŠãƒƒãƒ„ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ã§ã™ã€‚", "difficulty": 2},
        {"english": "Could we have the check, please?", "japanese": "ãŠä¼šè¨ˆã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚", "difficulty": 1},
        {"english": "The food was delicious!", "japanese": "æ–™ç†ãŒã¨ã¦ã‚‚ç¾å‘³ã—ã‹ã£ãŸã§ã™ï¼", "difficulty": 2},
    ],
    "Hotel": [
        {"english": "I have a reservation under the name...", "japanese": "...ã®åå‰ã§äºˆç´„ã—ã¦ã„ã¾ã™ã€‚", "difficulty": 2},
        {"english": "What time is check-out?", "japanese": "ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆã¯ä½•æ™‚ã§ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "Could you call a taxi for me?", "japanese": "ã‚¿ã‚¯ã‚·ãƒ¼ã‚’å‘¼ã‚“ã§ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ", "difficulty": 2},
        {"english": "Is breakfast included?", "japanese": "æœé£Ÿã¯å«ã¾ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "The air conditioning isn't working.", "japanese": "ã‚¨ã‚¢ã‚³ãƒ³ãŒå‹•ãã¾ã›ã‚“ã€‚", "difficulty": 2},
        {"english": "Could I get extra towels?", "japanese": "ã‚¿ã‚ªãƒ«ã‚’è¿½åŠ ã§ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ", "difficulty": 2},
    ],
    "Transportation": [
        {"english": "Where is the nearest subway station?", "japanese": "æœ€å¯„ã‚Šã®åœ°ä¸‹é‰„é§…ã¯ã©ã“ã§ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "How much is a ticket to...?", "japanese": "...ã¾ã§ã®ãƒã‚±ãƒƒãƒˆã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "What time does the last train leave?", "japanese": "æœ€çµ‚é›»è»Šã¯ä½•æ™‚ã§ã™ã‹ï¼Ÿ", "difficulty": 2},
        {"english": "I missed my flight.", "japanese": "é£›è¡Œæ©Ÿã«ä¹—ã‚Šé…ã‚Œã¾ã—ãŸã€‚", "difficulty": 2},
        {"english": "Is this seat taken?", "japanese": "ã“ã®å¸­ã¯ç©ºã„ã¦ã„ã¾ã™ã‹ï¼Ÿ", "difficulty": 1},
        {"english": "Could you tell me when we reach...?", "japanese": "...ã«ç€ã„ãŸã‚‰æ•™ãˆã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ", "difficulty": 3},
    ]
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
def initialize_session_state():
    if 'user_data' not in st.session_state:
        st.session_state.user_data = load_user_data()
    if 'current_phrase' not in st.session_state:
        st.session_state.current_phrase = None
    if 'current_scene' not in st.session_state:
        st.session_state.current_scene = "Shopping"
    if 'study_mode' not in st.session_state:
        st.session_state.study_mode = "Browse"

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
def load_user_data():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        "progress": {},
        "study_history": [],
        "srs_schedule": {}
    }

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
def save_user_data():
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(st.session_state.user_data, f, ensure_ascii=False, indent=2)

# TTSéŸ³å£°ç”Ÿæˆ
def generate_tts_audio(text, lang='en'):
    try:
        tts = gTTS(text=text, lang=lang, slow=False)
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
            tts.save(tmp_file.name)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦HTMLåŸ‹ã‚è¾¼ã¿ç”¨ã«å¤‰æ›
            with open(tmp_file.name, 'rb') as audio_file:
                audio_bytes = audio_file.read()
                audio_base64 = base64.b64encode(audio_bytes).decode()
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(tmp_file.name)
            
            return audio_base64
    except Exception as e:
        st.error(f"éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# éŸ³å£°å†ç”ŸHTML
def create_audio_html(audio_base64):
    return f"""
    <audio controls>
        <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
        Your browser does not support the audio element.
    </audio>
    """

# SRSï¼ˆé–“éš”åå¾©å­¦ç¿’ï¼‰ã‚·ã‚¹ãƒ†ãƒ 
def calculate_next_review(difficulty, success):
    base_intervals = [1, 3, 7, 14, 30, 90]  # æ—¥æ•°
    
    if success:
        if difficulty < len(base_intervals) - 1:
            difficulty += 1
    else:
        difficulty = max(0, difficulty - 1)
    
    next_review = datetime.now() + timedelta(days=base_intervals[min(difficulty, len(base_intervals) - 1)])
    return next_review.isoformat(), difficulty

# å¾©ç¿’ãŒå¿…è¦ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å–å¾—
def get_due_phrases():
    current_time = datetime.now().isoformat()
    due_phrases = []
    
    for phrase_id, schedule_info in st.session_state.user_data["srs_schedule"].items():
        if schedule_info["next_review"] <= current_time:
            due_phrases.append(phrase_id)
    
    return due_phrases

# å­¦ç¿’è¨˜éŒ²ã®è¿½åŠ 
def add_study_record(phrase, scene, success, study_type):
    record = {
        "timestamp": datetime.now().isoformat(),
        "phrase": phrase["english"],
        "scene": scene,
        "success": success,
        "study_type": study_type
    }
    st.session_state.user_data["study_history"].append(record)
    
    # SRSã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°
    phrase_id = f"{scene}_{phrase['english']}"
    if phrase_id in st.session_state.user_data["srs_schedule"]:
        current_difficulty = st.session_state.user_data["srs_schedule"][phrase_id]["difficulty"]
    else:
        current_difficulty = 0
    
    next_review, new_difficulty = calculate_next_review(current_difficulty, success)
    st.session_state.user_data["srs_schedule"][phrase_id] = {
        "next_review": next_review,
        "difficulty": new_difficulty,
        "total_reviews": st.session_state.user_data["srs_schedule"].get(phrase_id, {}).get("total_reviews", 0) + 1
    }
    
    save_user_data()

# é€²æ—ã‚°ãƒ©ãƒ•ã®ä½œæˆ
def create_progress_chart():
    if not st.session_state.user_data["study_history"]:
        st.info("å­¦ç¿’è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç·´ç¿’ã—ã¦ã¿ã¦ãã ã•ã„ï¼")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    history = st.session_state.user_data["study_history"]
    df = pd.DataFrame(history)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df['date'] = df['timestamp'].dt.date
    
    # æ—¥åˆ¥å­¦ç¿’å›æ•°
    daily_counts = df.groupby('date').size().reset_index(name='count')
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # æ—¥åˆ¥å­¦ç¿’å›æ•°ã‚°ãƒ©ãƒ•
    ax1.plot(daily_counts['date'], daily_counts['count'], marker='o')
    ax1.set_title('Daily Study Count')
    ax1.set_xlabel('Date')
    ax1.set_ylabel('Number of Phrases Studied')
    ax1.tick_params(axis='x', rotation=45)
    
    # ã‚·ãƒ¼ãƒ³åˆ¥æˆåŠŸç‡
    scene_success = df.groupby('scene')['success'].mean().reset_index()
    ax2.bar(scene_success['scene'], scene_success['success'])
    ax2.set_title('Success Rate by Scene')
    ax2.set_xlabel('Scene')
    ax2.set_ylabel('Success Rate')
    ax2.set_ylim(0, 1)
    ax2.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    st.pyplot(fig)

# éŸ³å£°èªè­˜ç”¨ã®è¨­å®š
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# éŸ³å£°å‡¦ç†ã‚¯ãƒ©ã‚¹
class AudioProcessor:
    def __init__(self):
        self.audio_frames = []
        self.is_recording = False
        
    def recv(self, frame):
        if self.is_recording:
            sound = frame.to_ndarray()
            self.audio_frames.append(sound)
        return frame

# éŸ³å£°èªè­˜ã¨ç™ºéŸ³è©•ä¾¡
def recognize_speech_and_evaluate(audio_data, target_phrase):
    try:
        # éŸ³å£°èªè­˜
        recognizer = sr.Recognizer()
        
        # AudioSegmentã‹ã‚‰wavå½¢å¼ã«å¤‰æ›
        audio_segment = AudioSegment.from_file(io.BytesIO(audio_data))
        wav_data = io.BytesIO()
        audio_segment.export(wav_data, format="wav")
        wav_data.seek(0)
        
        # éŸ³å£°èªè­˜å®Ÿè¡Œ
        with sr.AudioFile(wav_data) as source:
            audio = recognizer.record(source)
        
        recognized_text = recognizer.recognize_google(audio, language='en-US')
        
        # ç™ºéŸ³è©•ä¾¡ï¼ˆé¡ä¼¼åº¦è¨ˆç®—ï¼‰
        similarity = calculate_similarity(recognized_text.lower(), target_phrase.lower())
        
        return {
            "recognized_text": recognized_text,
            "similarity": similarity,
            "success": similarity > 0.7
        }
        
    except sr.UnknownValueError:
        return {
            "recognized_text": "éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ",
            "similarity": 0.0,
            "success": False
        }
    except sr.RequestError as e:
        return {
            "recognized_text": f"éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: {e}",
            "similarity": 0.0,
            "success": False
        }
    except Exception as e:
        return {
            "recognized_text": f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}",
            "similarity": 0.0,
            "success": False
        }

# ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦è¨ˆç®—
def calculate_similarity(text1, text2):
    return SequenceMatcher(None, text1, text2).ratio()

# éŸ³å£°éŒ²éŸ³ã¨WebRTC
def show_voice_recording_ui(target_phrase):
    st.subheader("ğŸ¤ Voice Recording Practice")
    
    st.write(f"**Target phrase:** {target_phrase}")
    st.write("Click 'Start Recording' and speak the phrase clearly.")
    
    # WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒãƒ¼ã®è¨­å®š
    webrtc_ctx = webrtc_streamer(
        key="speech-recognition",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=256,
        rtc_configuration=RTC_CONFIGURATION,
        media_stream_constraints={"video": False, "audio": True},
    )
    
    if webrtc_ctx.audio_receiver:
        st.write("ğŸ¤ Recording in progress...")
        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        if st.button("ğŸ›‘ Stop Recording and Analyze"):
            audio_frames = []
            
            # WebRTCã‹ã‚‰éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
            while True:
                try:
                    audio_frames.append(webrtc_ctx.audio_receiver.get_frame(timeout=1))
                except:
                    break
            
            if audio_frames:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                sound_data = []
                for frame in audio_frames:
                    sound = frame.to_ndarray()
                    sound_data.append(sound)
                
                if sound_data:
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚¤ãƒˆé…åˆ—ã«å¤‰æ›
                    combined_audio = np.concatenate(sound_data)
                    
                    # AudioSegmentã§å‡¦ç†
                    audio_segment = AudioSegment(
                        combined_audio.tobytes(),
                        frame_rate=frame.sample_rate,
                        sample_width=combined_audio.dtype.itemsize,
                        channels=1
                    )
                    
                    # éŸ³å£°èªè­˜ã¨è©•ä¾¡
                    audio_buffer = io.BytesIO()
                    audio_segment.export(audio_buffer, format="wav")
                    audio_buffer.seek(0)
                    
                    result = recognize_speech_and_evaluate(audio_buffer.read(), target_phrase)
                    
                    # çµæœè¡¨ç¤º
                    st.write("### ğŸ¯ Recognition Results")
                    st.write(f"**Recognized:** {result['recognized_text']}")
                    st.write(f"**Similarity:** {result['similarity']:.2%}")
                    
                    if result['success']:
                        st.success("ğŸ‰ Great pronunciation! Well done!")
                        st.balloons()
                    else:
                        st.warning("ğŸ”„ Keep practicing! Try speaking more clearly.")
                    
                    return result
            else:
                st.warning("No audio data received. Please try recording again.")
    
    return None

# ç°¡å˜ãªéŒ²éŸ³æ©Ÿèƒ½ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç‰ˆï¼‰
def show_simple_recording_ui(target_phrase):
    st.subheader("ğŸ¤ Voice Practice (Upload Audio)")
    
    st.write(f"**Target phrase:** {target_phrase}")
    st.info("Record yourself saying the phrase and upload the audio file (WAV, MP3, M4A supported)")
    
    uploaded_file = st.file_uploader(
        "Upload your recording",
        type=['wav', 'mp3', 'm4a', 'ogg'],
        help="Record the phrase and upload your audio file"
    )
    
    if uploaded_file is not None:
        st.audio(uploaded_file, format='audio/wav')
        
        if st.button("ğŸ¯ Analyze Pronunciation"):
            with st.spinner("Analyzing your pronunciation..."):
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                audio_data = uploaded_file.read()
                
                # éŸ³å£°èªè­˜ã¨è©•ä¾¡
                result = recognize_speech_and_evaluate(audio_data, target_phrase)
                
                # çµæœè¡¨ç¤º
                st.write("### ğŸ¯ Recognition Results")
                st.write(f"**Target:** {target_phrase}")
                st.write(f"**Recognized:** {result['recognized_text']}")
                st.write(f"**Similarity:** {result['similarity']:.2%}")
                
                # ç™ºéŸ³ã‚¹ã‚³ã‚¢è¡¨ç¤º
                if result['similarity'] >= 0.9:
                    st.success("ğŸ† Excellent pronunciation! Perfect!")
                    st.balloons()
                    score = "Excellent"
                elif result['similarity'] >= 0.7:
                    st.success("ğŸ‰ Good pronunciation! Well done!")
                    score = "Good"
                elif result['similarity'] >= 0.5:
                    st.warning("ğŸ”„ Needs improvement. Keep practicing!")
                    score = "Needs Practice"
                else:
                    st.error("ğŸ” Try again. Speak more clearly.")
                    score = "Poor"
                
                # ç™ºéŸ³ç·´ç¿’è¨˜éŒ²
                return {
                    "recognized_text": result['recognized_text'],
                    "similarity": result['similarity'],
                    "success": result['success'],
                    "score": score
                }
    
    return None

# ãƒ¡ã‚¤ãƒ³ç”»é¢
def main():
    st.title("ğŸ—£ï¸ English Conversation Practice App")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.title("ğŸ“š Navigation")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ãƒšãƒ¼ã‚¸ã‚’ç®¡ç†
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "ğŸ  Home"
    
    page = st.sidebar.selectbox("Choose a page:", 
                               ["ğŸ  Home", "ğŸ“– Study Phrases", "ğŸ”„ SRS Review", "ğŸ“Š Progress", "âš™ï¸ Settings"],
                               index=["ğŸ  Home", "ğŸ“– Study Phrases", "ğŸ”„ SRS Review", "ğŸ“Š Progress", "âš™ï¸ Settings"].index(st.session_state.current_page))
    
    # ãƒšãƒ¼ã‚¸ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯æ›´æ–°
    if page != st.session_state.current_page:
        st.session_state.current_page = page
        st.rerun()
    
    if st.session_state.current_page == "ğŸ  Home":
        show_home()
    elif st.session_state.current_page == "ğŸ“– Study Phrases":
        show_study_phrases()
    elif st.session_state.current_page == "ğŸ”„ SRS Review":
        show_srs_review()
    elif st.session_state.current_page == "ğŸ“Š Progress":
        show_progress()
    elif st.session_state.current_page == "âš™ï¸ Settings":
        show_settings()

def show_home():
    st.header("Welcome to English Conversation Practice! ğŸ‰")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ˆ Your Stats")
        total_studied = len(st.session_state.user_data["study_history"])
        due_count = len(get_due_phrases())
        st.metric("Total Phrases Studied", total_studied)
        st.metric("Due for Review", due_count)
    
    with col2:
        st.subheader("ğŸ¯ Quick Actions")
        
        # Start Studying ãƒœã‚¿ãƒ³
        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            start_study = st.button("ğŸ“– Study", type="primary", use_container_width=True)
        with col_btn2:
            if due_count > 0:
                start_review = st.button(f"ğŸ”„ Review ({due_count})", type="secondary", use_container_width=True)
            else:
                start_review = False
        
        # ãƒšãƒ¼ã‚¸é·ç§»å‡¦ç†
        if start_study:
            st.session_state.current_page = "ğŸ“– Study Phrases"
            st.rerun()
        
        if start_review:
            st.session_state.current_page = "ğŸ”„ SRS Review"
            st.rerun()
    
    st.subheader("ğŸ“ Available Scenes")
    scene_cols = st.columns(len(PHRASE_DATABASE))
    
    for i, (scene, phrases) in enumerate(PHRASE_DATABASE.items()):
        with scene_cols[i]:
            st.write(f"**{scene}**")
            st.write(f"{len(phrases)} phrases")

def show_study_phrases():
    st.header("ğŸ“– Study Phrases")
    
    # ã‚·ãƒ¼ãƒ³é¸æŠ
    scene = st.selectbox("Choose a scene:", list(PHRASE_DATABASE.keys()))
    phrases = PHRASE_DATABASE[scene]
    
    # ãƒ•ãƒ¬ãƒ¼ã‚ºé¸æŠ
    phrase_options = [f"{i+1}. {phrase['english']}" for i, phrase in enumerate(phrases)]
    selected_idx = st.selectbox("Choose a phrase:", range(len(phrase_options)), 
                               format_func=lambda x: phrase_options[x])
    
    current_phrase = phrases[selected_idx]
    
    # ãƒ•ãƒ¬ãƒ¼ã‚ºè¡¨ç¤º
    st.subheader("ğŸ“ Current Phrase")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**English:**")
        st.write(f"*{current_phrase['english']}*")
        
        # éŸ³å£°å†ç”Ÿãƒœã‚¿ãƒ³
        if st.button("ğŸ”Š Play Audio"):
            with st.spinner("Generating audio..."):
                audio_base64 = generate_tts_audio(current_phrase['english'])
                if audio_base64:
                    st.markdown(create_audio_html(audio_base64), unsafe_allow_html=True)
    
    with col2:
        show_japanese = st.checkbox("Show Japanese Translation")
        if show_japanese:
            st.write("**Japanese:**")
            st.write(current_phrase['japanese'])
    
    # ç·´ç¿’ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ¯ Practice")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("âœ… I know this phrase", type="primary"):
            add_study_record(current_phrase, scene, True, "self_assessment")
            st.success("Great! Phrase marked as known.")
            st.balloons()
    
    with col2:
        if st.button("âŒ I need more practice", type="secondary"):
            add_study_record(current_phrase, scene, False, "self_assessment")
            st.info("No worries! Keep practicing.")
    
    # éŒ²éŸ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ¤ Voice Practice")
    
    recording_method = st.radio(
        "Choose recording method:",
        ["Upload Audio File", "Real-time Recording (WebRTC)"],
        help="Upload: Record with your device and upload. WebRTC: Record directly in browser."
    )
    
    if recording_method == "Upload Audio File":
        recording_result = show_simple_recording_ui(current_phrase['english'])
    else:
        recording_result = show_voice_recording_ui(current_phrase['english'])
    
    # éŒ²éŸ³çµæœã‚’å­¦ç¿’è¨˜éŒ²ã«è¿½åŠ 
    if recording_result:
        add_study_record(current_phrase, scene, recording_result['success'], "pronunciation_practice")
        
        # ç™ºéŸ³ã‚¹ã‚³ã‚¢ã®è©³ç´°è¡¨ç¤º
        st.subheader("ğŸ“Š Pronunciation Analysis")
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Similarity Score", f"{recording_result['similarity']:.1%}")
            st.metric("Pronunciation Grade", recording_result.get('score', 'N/A'))
        
        with col2:
            if 'recognized_text' in recording_result:
                st.write("**What you said:**")
                st.write(f"_{recording_result['recognized_text']}_")
                st.write("**Target phrase:**")
                st.write(f"_{current_phrase['english']}_")

def show_srs_review():
    st.header("ğŸ”„ SRS Review")
    
    due_phrases = get_due_phrases()
    
    if not due_phrases:
        st.success("ğŸ‰ No phrases due for review! Great job!")
        return
    
    st.write(f"**{len(due_phrases)} phrases** are due for review.")
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠ
    if 'review_phrase_id' not in st.session_state:
        st.session_state.review_phrase_id = random.choice(due_phrases)
    
    phrase_id = st.session_state.review_phrase_id
    scene, phrase_text = phrase_id.split('_', 1)
    
    # ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ¤œç´¢
    current_phrase = None
    for phrase in PHRASE_DATABASE[scene]:
        if phrase['english'] == phrase_text:
            current_phrase = phrase
            break
    
    if current_phrase:
        st.subheader("ğŸ“ Review This Phrase")
        
        # è‹±èªã‚’éš ã—ã¦æ—¥æœ¬èªã‹ã‚‰ç·´ç¿’
        st.write("**Japanese:**")
        st.write(f"*{current_phrase['japanese']}*")
        
        if st.button("ğŸ” Show English"):
            st.write("**English:**")
            st.write(f"*{current_phrase['english']}*")
            
            # éŸ³å£°å†ç”Ÿ
            with st.spinner("Generating audio..."):
                audio_base64 = generate_tts_audio(current_phrase['english'])
                if audio_base64:
                    st.markdown(create_audio_html(audio_base64), unsafe_allow_html=True)
        
        # è©•ä¾¡ãƒœã‚¿ãƒ³
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("âœ… Easy", type="primary"):
                add_study_record(current_phrase, scene, True, "srs_review")
                st.success("Excellent! Next review scheduled.")
                # æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã¸
                remaining_due = [p for p in due_phrases if p != phrase_id]
                if remaining_due:
                    st.session_state.review_phrase_id = random.choice(remaining_due)
                    st.rerun()
                else:
                    st.session_state.review_phrase_id = None
                    st.rerun()
        
        with col2:
            if st.button("âŒ Hard", type="secondary"):
                add_study_record(current_phrase, scene, False, "srs_review")
                st.info("Review scheduled sooner. Keep practicing!")
                # æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã¸
                remaining_due = [p for p in due_phrases if p != phrase_id]
                if remaining_due:
                    st.session_state.review_phrase_id = random.choice(remaining_due)
                    st.rerun()
                else:
                    st.session_state.review_phrase_id = None
                    st.rerun()

def show_progress():
    st.header("ğŸ“Š Your Progress")
    
    # çµ±è¨ˆæƒ…å ±
    col1, col2, col3 = st.columns(3)
    
    total_studied = len(st.session_state.user_data["study_history"])
    if total_studied > 0:
        success_rate = sum(1 for record in st.session_state.user_data["study_history"] if record["success"]) / total_studied
        
        with col1:
            st.metric("Total Phrases Studied", total_studied)
        
        with col2:
            st.metric("Success Rate", f"{success_rate:.1%}")
        
        with col3:
            st.metric("Days Studied", len(set(record["timestamp"][:10] for record in st.session_state.user_data["study_history"])))
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    st.subheader("ğŸ“ˆ Learning Charts")
    create_progress_chart()
    
    # æœ€è¿‘ã®å­¦ç¿’è¨˜éŒ²
    st.subheader("ğŸ“ Recent Study History")
    if st.session_state.user_data["study_history"]:
        recent_records = st.session_state.user_data["study_history"][-10:]  # æœ€æ–°10ä»¶
        for record in reversed(recent_records):
            status = "âœ…" if record["success"] else "âŒ"
            st.write(f"{status} **{record['scene']}**: {record['phrase']} _{record['timestamp'][:16]}_")
    else:
        st.info("No study records yet. Start practicing to see your progress!")

def show_settings():
    st.header("âš™ï¸ Settings")
    
    st.subheader("ğŸ“Š Data Management")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“¥ Export Data"):
            data_str = json.dumps(st.session_state.user_data, ensure_ascii=False, indent=2)
            st.download_button(
                label="Download Data",
                data=data_str,
                file_name="english_practice_data.json",
                mime="application/json"
            )
    
    with col2:
        if st.button("ğŸ—‘ï¸ Clear All Data", type="secondary"):
            if st.checkbox("I confirm I want to delete all data"):
                st.session_state.user_data = {
                    "progress": {},
                    "study_history": [],
                    "srs_schedule": {}
                }
                save_user_data()
                st.success("All data cleared!")
                st.rerun()
    
    st.subheader("â„¹ï¸ About")
    st.write("""
    **English Conversation Practice App**
    
    Features:
    - ğŸ“– Scene-based phrase collections
    - ğŸ”Š Native pronunciation with TTS
    - ğŸ”„ Spaced Repetition System (SRS)
    - ğŸ“Š Progress tracking and charts
    - ğŸ¤ Voice recognition support
    
    Created with Streamlit and Python.
    """)

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
if __name__ == "__main__":
    initialize_session_state()
    main()